   \section{Problem Statement}
\textbf{context etc here...}
\begin{comment}
\textbf{context:}
Advances in hardware and manufacturing have made autonomous and semi-autonomous robots more available. Use in industry and even general public has increased. Full autonomous robots are still limited to structured environments and tasks such as in factories and warehouses.
Before robots can operate autonomously in unstructured environments, new sensor models are required to more effectively observe and represent complex environment states. \textbf{TODO:} \textit{Why are new sensor models required? Check if this is covered in literature review. If not, need to expand on this.}

\textbf{problem/lacking:}
One method of estimating the state of the environment is to use a state observer. The majority of observer implementations do not take into account the natural symmetries of the dynamics of the state. Doing so has shown to be beneficial in both the design of observers, and improved convergence properties.
However, these invariant observer methods are still limited to finite dimensional systems. In many implementations involving infinite-dimensional systems, the system is discretised to a finite dimensional one prior to observer design.  \textbf{TODO:} \textit{How does this influence performance?}

What is needed is a theory of infinite dimensional, symmetry preserving observers, + design principles.

\textbf{what will this theory provide?:}
This theory will simplify invariant observer design for infinite dimensional systems. Only discretising after observer design will maximise the potential of dense sensors. This will allow for more accurate and fast estimation of complex environments,

\textbf{approach:}
This project aims to develop some of this theory. The approach taken will be to design an invariant observer for a specific infinite dimensional system, before generalising the results.
\end{comment}

\textbf{estimation problem - cube pose \& size:}\\
\input{Figures/fig_cubeproblem}
This report will solve a particular estimation problem before generalising the results to a wider class of systems. A situation in which an infinite dimensional observer would be useful is in the estimation of the pose of an object of size moving in an environment of unknown state.
For example, consider an autonomous robot deployed in an agricultural survey, which must determine the position and size of a certain crop.

The problem to be investigated is shown in Figure~\ref{fig:cubeproblem}. A 2D scanning range sensor moves through an environment consisting of a target object of known shape, in this case a rigid cube, and an unknown background which may consist of one or more rigid bodies. The state of the sensor is known, but the states of the cube and background environment are unknown. The goal is to use the state of the sensor and the range measurements it provides to estimate the state of the cube.

The frames used to describe the motion of the rigid bodies in this problem are:
\begin{itemize}
\item $\{F\}$ - the inertial (fixed) frame. For the purposes of this problem, the inertial frame is a frame whose motion is negligible. For the practical experiment this frame will be fixed to the ground.
\item $\{A\}$ - the frame fixed to the sensor. The origin of this frame is the centre of rotation of the sensor's scan direction. The axes of $\{A\}$ are fixed to the sensor according to figure \textbf{TODO: FIGURE}. The transformation from $\{F\}$ to $\{A\}$ at time $t$ is defined by the screw matrix of the sensor $\mathbf{S}_{s}(t)$.
\item $\{B\}$ - the frame fixed to the cube. The origin of $\{B\}$ coincides with the centre of the cube and is aligned so that each axis intersects with the centre of a face of the cube. The transformation from $\{F\}$ to $\{B\}$ at time $t$ is defined by the screw matrix of the cube $\mathbf{S}_{c}(t)$.
\end{itemize} 

The sensor provides measurements of the range $r$ to the nearest object from the sensor (either the cube or the background) in the direction $\mathbf{s}(t)$. 
The state of the sensor $\mathbf{X}_{s}(t)$ is defined as:
\begin{equation}
	\mathbf{X}_{s}(t) = 
	\{{^{F}_{F}\mathbf{S}^{}_{A}(t)},{^{A}_{F}\mathbf{T}^{}_{A}(t)},{^{A}_{F}\mathbf{W}^{}_{A}(t)},
	{^{A}\mathbf{s}(t)}\}
\end{equation}
The screw matrix represents the transformation from $\{A\}$ to $\{F\}$, defined in $\{F\}$. The twist and wrench matrices, as well as the scan direction $\mathbf{n}(t)$ are defined in terms of$\{A\}$.
For simplicity, this will be denoted 
\begin{equation}
	\mathbf{X}_{s}(t) = 
	\{\mathbf{S}_{s}(t),\mathbf{T}_{s}(t),\mathbf{W}_{s}(t),{^{A}\mathbf{s}(t)}\}
\end{equation}

The direction of measurement ${^{A}\mathbf{s}(t)}$ varies as a rotation about the z-axis of $\{A\}$. This 2D scanning motion depends on the model of the sensor used and is described in more detail in ADD REFERENCE. For simplification, the motion of the sensor itself with respect to $\{F\}$ will be limited to rotation about the $y$-axis of $\{F\}$.

\textbf{TODO: DIAGRAM SHOWING RESTRICTED MOTION}

The state of cube $\mathbf{X}_{c}(t)$ is defined as 
\begin{equation}
	\mathbf{X}_{c}(t) = 
	\{{^{F}_{F}\mathbf{S}^{}_{B}(t)},{^{B}_{F}\mathbf{T}^{}_{B}(t)},{^{B}_{F}\mathbf{W}^{}_{B}(t)},
	l\}
\end{equation}
For simplicity, this will be denoted
\begin{equation}
	\mathbf{X}_{c}(t) = 
	\{\mathbf{S}_{c}(t),\mathbf{T}_{c}(t),\mathbf{W}_{c}(t),l\}
\end{equation}
The range measurements do not indicate whether the object detected is the cube or a background object. Though the pose of the cube and environment remain unknown, for simplification, it is assumed that either:
\begin{itemize}
\item the cube is within a distance $d$ from the sensor and background objects are at least a distance $d$ away
\item these target and background objects do not touch or overlap and their surfaces are continuous functions on $\mathbb{R}^3$
\end{itemize}
For simulated data, only the first assumption is necessary. For experimental data sets the environment is more complex so the second assumption is required to identify range measurements corresponding to the cube. 

The aim is to design an observer which estimates the state of the cube from the pose of the sensor, as well as $\mathbf{n}$ and $r$. ie observer function $f$ such that:
\begin{equation}
	\hat{\mathbf{X}}_{c} = f(\mathbf{X}_{s},r(t)-\hat{r}(t))
\end{equation}

*convergence - how to quantify performance?









\textbf{deliverables:} \\
%The primary deliverable of this project is the observer design and simulation. Will later try to develop some general theory from this specific case. Will validate simulation with experiment using Hokuyo UBG 04-LX sensor, ??? robot arms and cubes of various sizes and materials.
%\textbf{TODO:} \textit{More detail, + be careful about what you promise}

