\chapter{Problem Statement}
Context - research into infinite dimensional, symmetry preserving observers.

Goals:
	are to explore aspects of this research. 
	Dense sensor. See if sparse sensor can be used as dense sensor.
	see where this research can improve

Approach: 
	solve simplified, problem
	early lumping - represent infinite dimensional system as finite dimensional
	still taking infinite dimensional measurements - similar to Adarve \cite{adarvefiltering}.

\textbf{estimation problem - cube pose \& size:}\\
\input{Figures/fig_cubeproblem}
A situation in which an infinite dimensional observer would be useful is in the estimation of the pose of an object of size moving in an environment of unknown state.
For example, consider an autonomous robot deployed in an agricultural survey, which must determine the position and size of a certain crop. Using a geometric model for the general shape of the crop, an aerial vehicle that could routinely detect and characterise the position and size of specimens would be useful in monitoring growth and during harvesting.

The problem to be investigated is shown in Figure~\ref{fig:cubeproblem}. A 2D scanning range sensor moves through an environment consisting of a target object of known shape, in this case a rigid cube, and an unknown background which may consist of one or more rigid bodies. The state of the sensor is known, but the states of the cube and background environment are unknown. The goal is to use the state of the sensor and the range measurements it provides to estimate the state of the cube.

The frames used to describe the motion of the rigid bodies in this problem are:
\begin{itemize}
\item $\{F\}$ - the inertial (fixed) frame. For the purposes of this problem, the inertial frame is a frame whose motion is negligible. For the practical experiment this frame will be fixed to the ground.
\item $\{A\}$ - the frame fixed to the sensor. The origin of this frame is the centre of rotation of the sensor's scan direction. The axes of $\{A\}$ are fixed to the sensor according to Figure \ref{fig:scanningparameters} in chapter \ref{chap:simulation}. The transformation from $\{F\}$ to $\{A\}$ at time $t$ is defined by the screw matrix of the sensor $\mathbf{S}_{s}(t)$.
\item $\{B\}$ - the frame fixed to the cube. The origin of $\{B\}$ coincides with the centre of the cube and is aligned so that each axis intersects with the centre of a face of the cube. The transformation from $\{F\}$ to $\{B\}$ at time $t$ is defined by the screw matrix of the cube $\mathbf{S}_{c}(t)$.
\end{itemize} 

The sensor provides measurements of the range $r$ to the nearest object from the sensor (either the cube or the background) in the direction $\mathbf{d}(t)$. 
The state of the sensor $\mathbf{X}_{s}(t)$ is defined as:
\begin{equation}
	\mathbf{X}_{s}(t) = 
	\{{^{F}_{F}\mathbf{S}^{}_{A}(t)},{^{A}_{F}\mathbf{T}^{}_{A}(t)},{^{A}_{F}\mathbf{W}^{}_{A}(t)},
	{^{A}\mathbf{d}(t)}\}
\end{equation}
The screw matrix represents the transformation from $\{A\}$ to $\{F\}$, defined in $\{F\}$. The twist and wrench matrices, as well as the scan direction $\mathbf{d}(t)$ are defined in terms of$\{A\}$.
For simplicity, this will be denoted 
\begin{equation}
	\mathbf{X}_{s}(t) = 
	\{\mathbf{S}_{s}(t),\mathbf{T}_{s}(t),\mathbf{W}_{s}(t),{^{A}\mathbf{d}(t)}\}
\end{equation}

The direction of measurement ${^{A}\mathbf{d}(t)}$ varies as a rotation about the z-axis of $\{A\}$. This 2D scanning motion depends on the model of the sensor used and is described in more detail in ADD REFERENCE. For simplification, the motion of the sensor itself with respect to $\{F\}$ will be limited to rotation about the $y$-axis of $\{F\}$.

The state of cube $\mathbf{X}_{c}(t)$ is defined as 
\begin{equation}
	\mathbf{X}_{c}(t) = 
	\{{^{F}_{F}\mathbf{S}^{}_{B}(t)},{^{B}_{F}\mathbf{T}^{}_{B}(t)},{^{B}_{F}\mathbf{W}^{}_{B}(t)},
	s\}
\end{equation}
For simplicity, this will be denoted
\begin{equation}
	\mathbf{X}_{c}(t) = 
	\{\mathbf{S}_{c}(t),\mathbf{T}_{c}(t),\mathbf{W}_{c}(t),s\}
\end{equation}
The range measurements do not indicate whether the object detected is the cube or a background object. Though the pose of the cube and environment remain unknown, for simplification, it is assumed that either:
\begin{itemize}
\item the cube is within a distance $r_{max}$ from the sensor and background objects are at least a distance $r_{max}$ away
\item these target and background objects do not touch or overlap and their surfaces are continuous functions on $\mathbb{R}^3$
\end{itemize}
For simulated data, only the first assumption is necessary. For experimental data sets the environment is more complex so the second assumption is required to identify range measurements corresponding to the cube. 

The aim is to design an observer which estimates the state of the cube from the pose of the sensor, as well as scan direction $\mathbf{s}$ and range $r$. Ground truth range unavailable to observer - Will use range measurements $\tilde{r}$ and measurement prediction $\hat{r}$. Observer function $f$ such that:
\begin{equation}
	\hat{\mathbf{X}}_{c}(k+1) = f(\mathbf{X}_{s}(t),\hat{\mathbf{X}}_{c}(k),\tilde{r}(t),\hat{r}(t))
\end{equation}

\textbf{*RELATE THIS TO BACKGROUND ON OBSERVERS:}\\
-no input, nonlinear system
-state to estimate: state of cube
-measurement: range, also relates to state of sensor
can also think of this as state to estimate is relative state between sensor, cube
*convergence - how to quantify performance?
-innovation based on prediction and measured ranges SEPARATELY - this is because only trying to observe cube, ignoring environment. infinite dimensional observer would attempt to estimate infinite dimensional depth field, which is a function on sphere which returns depth - continuous. Instead uses knowledge of environment to filter it out. thus, necessary to have separate measurements, or would only be able to apply innovations when both visible - no solution in this case - couldn't correct size\\

\textbf{deliverables:} \\
sensor/body simulation
observer design
observer implementation
experimental validation

